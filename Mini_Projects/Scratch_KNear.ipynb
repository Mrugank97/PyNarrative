{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAiyDPvJMhjU"
      },
      "source": [
        "## **Project Description:**\n",
        "**Implementing and Evaluating a Custom K-Nearest Neighbors Classifier**<br>\n",
        "\n",
        "This project focuses on building and evaluating a custom K-Nearest Neighbors (KNN) classifier from scratch using Python. Here's a breakdown of the approach:\n",
        "\n",
        "**Implementation:**\n",
        "\n",
        "- **Distance Function:** A `distance` function is defined to calculate the Euclidean distance between two data points.\n",
        "- **K-Nearest Neighbors Class:** A `K_Near` class is created to represent the KNN classifier:\n",
        "    - **Constructor (`__init__`):** Initializes the `k` value (number of neighbors) used for classification.\n",
        "    - **`fit` method:** Stores the training data (`X_train`) and target labels (`y_train`) for future reference.\n",
        "    - **`predict` method:** This core method performs prediction for new data points (`X`):\n",
        "        1. Calculates the distances between the new data point and all data points in the training set.\n",
        "        2. Sorts the distances in ascending order to find the `k` nearest neighbors.\n",
        "        3. Identifies the most frequent class label (mode) among the `k` nearest neighbors.\n",
        "        4. Assigns this mode label as the predicted class for the new data point.\n",
        "- **Model Evaluation:** The script utilizes the Iris flower dataset (`load_iris`) for evaluation.\n",
        "    - Data is split into training and testing sets (`train_test_split`).\n",
        "    - The custom KNN model (`k_near`) is trained on the training data (`fit`).\n",
        "    - Predictions are made on the testing data (`predict`).\n",
        "    - Accuracy score (`accuracy_score`) and confusion matrix (`confusion_matrix`) are calculated to assess model performance.\n",
        "\n",
        "**Outcomes:**\n",
        "\n",
        "- This project demonstrates the implementation of a KNN classifier from scratch, allowing for a deeper understanding of the algorithm's core principles.\n",
        "- The evaluation using the Iris dataset provides insights into the model's effectiveness on a real-world classification task.\n",
        "- The confusion matrix helps visualize how well the model distinguishes between different flower classes.\n",
        "\n",
        "**Further Exploration:**\n",
        "\n",
        "- Experiment with different values of `k` to see how it affects KNN performance.\n",
        "- Implement distance metrics beyond Euclidean distance (e.g., Manhattan distance).\n",
        "- Compare the custom KNN model with scikit-learn's KNN implementation.\n",
        "- Explore more complex datasets and classification problems.\n",
        "\n",
        "By building and evaluating a custom KNN classifier, this project provides valuable hands-on experience with KNN and lays the foundation for further exploration of machine learning algorithms.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSmnK_g1P10F",
        "outputId": "1c13fbe8-58f5-4289-de82-6b8c5aaabc64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:89.47368421052632%\n",
            "\n",
            "Confusion Matrix:\n",
            "[[10  0  0]\n",
            " [ 0 14  4]\n",
            " [ 0  0 10]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "def distance(x1,x2):\n",
        "    return np.sqrt(np.sum((x1-x2)**2))\n",
        "\n",
        "class K_Near:\n",
        "    def __init__(self,k=5):\n",
        "        self.k=k\n",
        "\n",
        "    def fit(self,X,y):\n",
        "        self.X_train=X\n",
        "        self.y_train=y\n",
        "\n",
        "    def predict(self,X):\n",
        "        y_predict=[]\n",
        "        for i in range(len(X)):\n",
        "            distances=[distance(X[i],x) for x in self.X_train]\n",
        "            index=np.argsort(distances)[:self.k]\n",
        "            label=[self.y_train[i] for i in index]\n",
        "            common=max(set(label),key=label.count)\n",
        "            y_predict.append(common)\n",
        "        return np.array(y_predict)\n",
        "\n",
        "iris=load_iris()\n",
        "X_train,X_test,y_train,y_test=train_test_split(iris.data,iris.target,test_size=0.25)\n",
        "\n",
        "k_near=K_Near(k=5)\n",
        "k_near.fit(X_train,y_train)\n",
        "y_predict=k_near.predict(X_test)\n",
        "\n",
        "accuracy=accuracy_score(y_test,y_predict)\n",
        "matrix=confusion_matrix(y_test,y_predict)\n",
        "\n",
        "print(f\"Accuracy:{accuracy*100}%\\n\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(matrix)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
